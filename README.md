# ğŸš€ MENTOR: Efficient Multimodal-Conditioned Tuning for Autoregressive Vision Generation

<div align="center">

[![NeurIPS 2024](https://img.shields.io/badge/NeurIPS-2024-blue.svg?style=for-the-badge)](https://arxiv.org/abs/XXXX.XXXXX)
[![Project Page](https://img.shields.io/badge/Project-Page-green.svg?style=for-the-badge)](https://mentor.github.io)
[![Hugging Face](https://img.shields.io/badge/ğŸ¤—-Models-yellow.svg?style=for-the-badge)](https://huggingface.co/MENTOR)
[![Demo](https://img.shields.io/badge/ğŸ¯-Demo-red.svg?style=for-the-badge)](https://huggingface.co/spaces/MENTOR/demo)

<h3>ğŸ† State-of-the-Art Multimodal Image Generation with 10Ã— Less Data</h3>

<p align="center">
  <img src="figures/teasarv3.png" width="90%" alt="MENTOR Overview" />
</p>

**[ğŸ“„ Paper](https://arxiv.org/abs/XXXX.XXXXX)** | **[ğŸ¬ Video](https://youtube.com)** | **[ğŸ’» Code](#installation)** | **[ğŸ¤— Models](https://huggingface.co/MENTOR)** | **[ğŸ“Š Results](#main-results)**

</div>

---

## ğŸ¯ Why MENTOR?

<div align="center">
<table>
<tr>
<th>ğŸ”¥ 10Ã— Less Training Data</th>
<th>âš¡ 170Ã— Faster Training</th>
<th>ğŸ’ª Better Performance</th>
</tr>
<tr>
<td align="center">3M vs 16-200M samples</td>
<td align="center">1.5 days vs 256 GPU-days</td>
<td align="center">47% vs 36% CPÂ·PF score</td>
</tr>
</table>
</div>

**MENTOR** revolutionizes multimodal image generation by achieving superior results with dramatically reduced resources. While competitors like Emu2 require 37B parameters and massive datasets, MENTOR delivers better performance with just 2.3B parameters.

<details>
<summary><b>ğŸ“‹ Table of Contents</b></summary>

- [Key Features](#-key-features)
- [Quick Start](#-quick-start)
- [Main Results](#-main-results)
- [Method Overview](#-method-overview)
- [Installation](#-installation)
- [Usage Examples](#-usage-examples)
- [Model Zoo](#-model-zoo)
- [Technical Details](#-technical-details)
- [Citation](#-citation)

</details>

---

## âœ¨ Key Features

<div align="center">

| Feature | MENTOR | Diffusion Models |
|---------|--------|------------------|
| **Training Efficiency** | âœ… 1.5 days on 8 GPUs | âŒ 3+ days on 256 GPUs |
| **Deterministic Control** | âœ… Precise AR generation | âŒ Stochastic sampling |
| **Modality Balance** | âœ… Lowest CP/PF ratio (0.65) | âŒ High imbalance (>1.0) |
| **Architecture** | âœ… Simple unified transformer | âŒ Complex auxiliary modules |
| **Multi-task Support** | âœ… Zero-shot adaptation | âŒ Task-specific tuning |

</div>

## ğŸš€ Quick Start

```bash
# Install MENTOR
pip install mentor-gen

# Generate with one line of code
from mentor import MENTOR
model = MENTOR.from_pretrained("MENTOR/mentor-mlp")
image = model.generate(
    text="A corgi wearing sunglasses on the beach",
    reference_image="path/to/corgi.jpg"
)
```

<div align="center">
  <a href="https://colab.research.google.com/drive/xxx" target="_blank">
    <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
  </a>
  <a href="https://huggingface.co/spaces/MENTOR/demo" target="_blank">
    <img src="https://img.shields.io/badge/ğŸ¤—-Try%20Demo-yellow.svg" alt="Hugging Face Demo"/>
  </a>
</div>

---

## ğŸ“Š Main Results

### ğŸ… DreamBench++ Benchmark Leadership

<p align="center">
<img src="figures/Figure.png" width="60%" alt="Performance Comparison">
</p>

<div align="center">

| Method | Model Size | Training Data | CPâ†‘ | PFâ†‘ | **CPÂ·PFâ†‘** | CP/PFâ†“ |
|:-------|:----------:|:-------------:|:---:|:---:|:----------:|:------:|
| Emu2 | 37B | 16M | 0.53 | 0.69 | 0.36 | 0.77 |
| DreamEngine | 10.5B | 21M | 0.68 | 0.37 | 0.26 | 1.84 |
| Kosmos-G | 3B | 200M | 0.54 | 0.51 | 0.28 | 1.06 |
| **MENTOR** | **2.3B** | **3M** | **0.55** | **0.84** | **0.47** | **0.65** |

</div>

> **CP**: Concept Preservation | **PF**: Prompt Following | **Lower CP/PF = Better Balance**

### ğŸ¨ Superior Image Reconstruction

<div align="center">

| Method | COCO L2â†“ | JourneyDB L2â†“ | Improvement |
|:-------|:--------:|:-------------:|:-----------:|
| DreamEngine | 0.2065 | 0.2052 | Baseline |
| **MENTOR** | **0.1008** | **0.0867** | **>50% Better** |

</div>

---

## ğŸ—ï¸ Method Overview

### Two-Stage Training Paradigm

<p align="center">
<img src="figures/model_stagev2.png" width="95%" alt="Model Architecture">
</p>

<div align="center">

| Stage | Purpose | Tasks | Training Time |
|:------|:--------|:------|:-------------:|
| **Stage 1** | Multimodal Alignment | â€¢ Image Reconstruction<br>â€¢ Object Segmentation<br>â€¢ T2I Generation | 14 hours |
| **Stage 2** | Instruction Tuning | â€¢ Image Recovery<br>â€¢ Subject-driven Gen<br>â€¢ Balanced Integration | 20 hours |

</div>

### Architecture Components

<details>
<summary><b>ğŸ”§ Click to expand technical architecture</b></summary>

#### Multimodal Encoder
- **Vision**: CLIP-Large-Patch14 (frozen)
- **Language**: FlanT5-XL 
- **Connector Options**:
  - **MLP-based**: Full visual detail preservation (256 tokens/image)
  - **Query-based**: Efficient token compression (32 tokens/image)

#### Autoregressive Decoder
- **Base Model**: LlamaGen-XL (775M parameters)
- **Vocabulary**: Shared with VQGAN tokenizer
- **Generation**: Deterministic next-token prediction

</details>

---

## ğŸ’» Installation

<details>
<summary><b>Requirements</b></summary>

- Python â‰¥ 3.8
- PyTorch â‰¥ 2.1.0
- CUDA â‰¥ 11.8
- 8Ã— NVIDIA A100 GPUs (80GB) for training
- 1Ã— GPU (24GB) for inference

</details>

```bash
# Clone repository
git clone https://github.com/HaozheZhao/MENTOR.git
cd MENTOR

# Install dependencies
pip install -r requirements.txt

# Download pretrained models
python scripts/download_models.py
```

---

## ğŸ¯ Usage Examples

### Basic Generation

```python
from mentor import MENTOR

# Load model
model = MENTOR.from_pretrained("MENTOR/mentor-mlp")

# Text-to-Image
image = model.generate(text="A majestic mountain at sunset")

# Subject-driven generation
image = model.generate(
    text="A dog playing piano",
    reference_image="path/to/dog.jpg"
)

# Multi-image generation (Query variant)
model_query = MENTOR.from_pretrained("MENTOR/mentor-query")
image = model_query.generate(
    text="Combine these styles",
    reference_images=["style1.jpg", "style2.jpg", "style3.jpg"]
)
```

### Advanced Features

<details>
<summary><b>ğŸ” Text-Guided Segmentation</b></summary>

```python
mask = model.segment(
    image="path/to/image.jpg",
    text="the red car"
)
```

</details>

<details>
<summary><b>ğŸ¨ In-Context Learning</b></summary>

```python
# Provide examples for few-shot adaptation
examples = [
    {"input": "sketch1.jpg", "output": "colored1.jpg"},
    {"input": "sketch2.jpg", "output": "colored2.jpg"}
]
result = model.in_context_generate(
    examples=examples,
    query="sketch3.jpg"
)
```

</details>

---

## ğŸ¤– Model Zoo

<div align="center">

| Model | Type | Context | Multi-Image | Download |
|:------|:-----|:-------:|:-----------:|:--------:|
| MENTOR-MLP | Full Detail | 256 tokens/img | âŒ | [ğŸ¤— HF Hub](https://huggingface.co/MENTOR/mentor-mlp) |
| MENTOR-Query | Efficient | 32 tokens/img | âœ… (14 imgs) | [ğŸ¤— HF Hub](https://huggingface.co/MENTOR/mentor-query) |
| MENTOR-Multi | Extended | 1280 tokens | âœ… (4 imgs) | [ğŸ¤— HF Hub](https://huggingface.co/MENTOR/mentor-multi) |

</div>

---

## ğŸ”¬ Technical Details

<details>
<summary><b>ğŸ“ Mathematical Formulation</b></summary>

### Training Objective
Given multimodal inputs **c** = {I, T}, the encoder Ï† produces:
```
H = MLP(Ï†(c)) = (hâ‚, ..., hâ‚˜) âˆˆ â„á´¹Ë£áµˆ
```

The AR decoder Î¸ generates image sequence **y**:
```
Î¸(y | H) = âˆáµ¢â‚Œâ‚á´¸ Î¸(yáµ¢ | y<áµ¢, H)
```

### Classifier-Free Guidance
- Training: Replace H with Háµ¤ with probability p = 0.1
- Inference: â„“_g = â„“_u + (â„“_c - â„“_u) Ã— Î»

</details>

<details>
<summary><b>ğŸ”§ Training Configuration</b></summary>

### Hyperparameters
- **Optimizer**: AdamW (Î²â‚=0.9, Î²â‚‚=0.999)
- **Learning Rate**: Stage 1: 5e-4, Stage 2: 1e-4
- **Batch Size**: 128 (global)
- **Warmup**: 5% of total steps
- **Schedule**: Cosine decay

### Hardware Requirements
- **Training**: 8Ã— A100 80GB (~34 hours total)
- **Inference**: 1Ã— GPU 24GB+ 
- **Memory**: ~60GB peak during training

</details>

<details>
<summary><b>ğŸ“Š Extended Results</b></summary>

### Ablation Studies

| Configuration | CP | PF | CPÂ·PF |
|:--------------|:--:|:--:|:-----:|
| Full Model | 0.555 | 0.839 | 0.466 |
| w/o Stage 1 | 0.179 | 0.673 | 0.120 |
| w/o Image Recovery | 0.661 | 0.284 | 0.188 |
| w/o Segmentation | 0.412 | 0.918 | 0.378 |

### ROPE Fix for LlamaGen
We identified and corrected a critical bug in LlamaGen's 2D ROPE implementation that was causing information loss. Our fix required retraining on the original datasets before fine-tuning.

</details>

---

## ğŸŒŸ Gallery

<details>
<summary><b>View more examples</b></summary>

### Image Reconstruction
<p align="center">
<img src="figures/reconstruction_exp.png" width="80%" alt="Image Reconstruction Examples">
</p>

### Multi-Subject Generation
<p align="center">
<img src="figures/multi_img.png" width="80%" alt="Multi-Subject Generation">
</p>

### In-Context Learning
<p align="center">
<img src="figures/icl_exp.png" width="80%" alt="In-Context Learning Examples">
</p>

</details>

---

## ğŸ“š Citation

If you find MENTOR useful, please cite our paper:

```bibtex
@inproceedings{zhao2024mentor,
  title={MENTOR: Efficient Multimodal-Conditioned Tuning for Autoregressive Vision Generation Models},
  author={Zhao, Haozhe* and Cai, Zefan* and Si, Shuzheng and Chen, Liang and 
          Gu, Jiuxiang and Xiao, Wen and Hu, Junjie},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2024}
}
```

---

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details.

## ğŸ“„ License

This project is licensed under the MIT License - see [LICENSE](LICENSE) for details.

## ğŸ™ Acknowledgments

We thank the teams behind LlamaGen, CLIP, FlanT5, and DreamBench++ for their foundational contributions.

---

<div align="center">
<p>
<a href="https://github.com/HaozheZhao/MENTOR/issues">ğŸ› Report Bug</a> â€¢
<a href="https://github.com/HaozheZhao/MENTOR/issues">ğŸ’¡ Request Feature</a> â€¢
<a href="https://discord.gg/mentor">ğŸ’¬ Join Discord</a>
</p>

<p><b>Made with â¤ï¸ by the MENTOR Team</b></p>
</div>