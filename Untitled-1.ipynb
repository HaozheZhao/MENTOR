{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python3 autoregressive/sample/sample_t2i.py --vq-ckpt ./pretrained_models/vq_ds16_t2i.pt --gpt-ckpt ./pretrained_models/t2i_XL_stage2_512.pt --gpt-model GPT-XL --image-size 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool, Manager\n",
    "\n",
    "# Define the root paths\n",
    "root_paths = [\n",
    "    \"/nobackup/zefan/projects/VLGen/segment_results_imgnet\",\n",
    "    \"/nobackup/zefan/projects/VLGen/segment_results_sam_molom\",\n",
    "    \"/nobackup/zefan/projects/VLGen/segment_results_sam\",\n",
    "]\n",
    "\n",
    "# Output file\n",
    "output_file = \"/nobackup/zefan/projects/VLGen/LlamaGen/metadata_all.jsonl\"\n",
    "\n",
    "# Function to recursively find and process metadata.jsonl\n",
    "def find_and_process_metadata(folder):\n",
    "    metadata_list = []\n",
    "    for root, _, files in tqdm(os.walk(folder)):\n",
    "        if \"metadata.jsonl\" in files:\n",
    "            metadata_path = os.path.join(root, \"metadata.jsonl\")\n",
    "            with open(metadata_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    metadata_list.append(json.loads(line.strip()))\n",
    "    return metadata_list\n",
    "\n",
    "# Function to collect metadata using multiprocessing\n",
    "def collect_metadata(folder):\n",
    "    try:\n",
    "        return find_and_process_metadata(folder)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing folder {folder}: {e}\")\n",
    "        return []\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    all_metadata = []\n",
    "    \n",
    "    # Use multiprocessing for faster traversal\n",
    "    with Manager() as manager:\n",
    "        metadata_list = manager.list()\n",
    "        with Pool(processes=os.cpu_count()) as pool:\n",
    "            results = list(tqdm(pool.imap(collect_metadata, root_paths), total=len(root_paths)))\n",
    "        \n",
    "        # Combine results into a single list\n",
    "        for result in results:\n",
    "            all_metadata.extend(result)\n",
    "    \n",
    "    # Save all metadata to a single JSONL file\n",
    "    with open(output_file, 'w') as out_f:\n",
    "        for item in all_metadata:\n",
    "            out_f.write(json.dumps(item) + '\\n')\n",
    "\n",
    "    print(f\"Metadata collected and saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469418/469418 [02:44<00:00, 2850.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total correct cases: 361253\n",
      "Total incorrect cases: 108165\n",
      "Reasons for incorrectness:\n",
      "similar_masks: 69745\n",
      "mask_too_small: 11648\n",
      "scattered_masks: 22238\n",
      "mask_too_large: 4510\n",
      "no_masks: 24\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter  \n",
    "from multiprocessing import Manager  \n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import numpy as np\n",
    "from scipy.ndimage import label\n",
    "# Paths\n",
    "input_file = \"/nobackup/zefan/projects/VLGen/LlamaGen/metadata_all.jsonl\"\n",
    "output_file_correct = \"/nobackup/zefan/projects/VLGen/LlamaGen/metadata_correct.jsonl\"\n",
    "output_file_incorrect = \"/nobackup/zefan/projects/VLGen/LlamaGen/metadata_incorrect.jsonl\"\n",
    "def is_similar(img1, img2, threshold=0.95, resize_dim=(32, 32)):\n",
    "    \"\"\"\n",
    "    Check if two images are similar by resizing, scaling back, and comparing pixel values.\n",
    "\n",
    "    Args:\n",
    "        img1, img2: PIL Image objects to compare.\n",
    "        threshold: Similarity threshold (default is 0.95).\n",
    "        resize_dim: Dimensions to resize the images to (default is 32x32).\n",
    "\n",
    "    Returns:\n",
    "        bool: True if images are similar, False otherwise.\n",
    "    \"\"\"\n",
    "    # Resize and scale back to original size\n",
    "    resized_img1 = img1.resize(resize_dim, Image.Resampling.LANCZOS)\n",
    "    resized_img2 = img2.resize(resize_dim, Image.Resampling.LANCZOS)\n",
    "\n",
    "    # Flatten and compare pixel arrays\n",
    "    arr1 = np.array(resized_img1).flatten()\n",
    "    arr2 = np.array(resized_img2).flatten()\n",
    "\n",
    "    # Compute similarity\n",
    "    return np.mean(arr1 == arr2) >= threshold\n",
    "def is_scattered(mask_path, min_connected_area=5, max_components=1000):\n",
    "    \"\"\"\n",
    "    检测 mask 是否为散点失败。\n",
    "\n",
    "    Args:\n",
    "        mask_path (str): mask 图片路径。\n",
    "        min_connected_area (int): 单个连通区域的最小像素数，低于此值认为是散点。\n",
    "        max_components (int): 最大允许的连通区域数量，超过此值认为是散点。\n",
    "    \n",
    "    Returns:\n",
    "        bool: 如果是散点情况，返回 True；否则返回 False。\n",
    "    \"\"\"\n",
    "    # 加载图片并转换为二值化数组\n",
    "    mask = Image.open(mask_path).convert(\"L\")\n",
    "    mask_array = np.array(mask) > 0  # 转换为布尔值，True 表示非零像素\n",
    "\n",
    "    # 计算连通域\n",
    "    labeled_array, num_features = label(mask_array)\n",
    "\n",
    "    # 统计连通域面积\n",
    "    component_sizes = np.bincount(labeled_array.ravel())[1:]  # 排除背景（label=0）\n",
    "\n",
    "    # 判断是否为散点\n",
    "    scattered = (\n",
    "        len(component_sizes) > max_components or  # 连通域数量过多\n",
    "        all(size < min_connected_area for size in component_sizes)  # 所有区域都过小\n",
    "    )\n",
    "    return scattered\n",
    "# Modify is_mask_valid to return a reason  \n",
    "def is_mask_valid(mask_paths):  \n",
    "    if len(mask_paths) == 1:  \n",
    "        return True, None  # Single mask is always valid  \n",
    "    elif len(mask_paths) == 0:  \n",
    "        return False, \"no_masks\"  \n",
    "\n",
    "    # Load masks  \n",
    "    masks = [Image.open(path) for path in mask_paths]  \n",
    "    mask_sizes = [np.sum(np.array(mask) > 0) for mask in masks]  \n",
    "    total_pixels = masks[0].size[0] * masks[0].size[1]  \n",
    "\n",
    "    # Check similarity  \n",
    "    for path in mask_paths:\n",
    "        if is_scattered(path):\n",
    "            return False, \"scattered_masks\" \n",
    "\n",
    "    for i, mask1 in enumerate(masks):  \n",
    "        for j, mask2 in enumerate(masks):  \n",
    "            if i < j and is_similar(mask1, mask2):  # Check similarity  \n",
    "                return False, \"similar_masks\"  \n",
    "\n",
    "    # Check size condition  \n",
    "    for size in mask_sizes:  \n",
    "        ratio = size / total_pixels  \n",
    "        if ratio < 0.003:  \n",
    "            return False, \"mask_too_small\"  \n",
    "        if ratio > 0.95:  \n",
    "            return False, \"mask_too_large\"  \n",
    "\n",
    "    return True, None  \n",
    "\n",
    "# Process a single JSON entry  \n",
    "def process_line(line):  \n",
    "    data = json.loads(line)  \n",
    "    mask_paths = data[\"mask_path\"]  \n",
    "\n",
    "    is_valid, reason = is_mask_valid(mask_paths)  \n",
    "    if is_valid:  \n",
    "        return \"correct\", data, None  \n",
    "    else:  \n",
    "        return \"incorrect\", data, reason  \n",
    "\n",
    "def process_file():  \n",
    "    with open(input_file, \"r\") as f:  \n",
    "        lines = f.readlines()  \n",
    "\n",
    "    correct_cases = []  \n",
    "    incorrect_cases = []  \n",
    "    \n",
    "    # Initialize reason counter  \n",
    "    reason_counter = Counter()  \n",
    "\n",
    "    with Pool(cpu_count()) as pool:  \n",
    "        results = list(tqdm(pool.imap(process_line, lines), total=len(lines)))  \n",
    "\n",
    "    for result_type, data, reason in results:  \n",
    "        if result_type == \"correct\":  \n",
    "            correct_cases.append(data)  \n",
    "        else:  \n",
    "            incorrect_cases.append(data)  \n",
    "            reason_counter[reason] += 1  \n",
    "\n",
    "    # Save results  \n",
    "    with open(output_file_correct, \"w\") as f_correct, open(output_file_incorrect, \"w\") as f_incorrect:  \n",
    "        for case in correct_cases:  \n",
    "            f_correct.write(json.dumps(case) + \"\\n\")  \n",
    "        for case in incorrect_cases:  \n",
    "            f_incorrect.write(json.dumps(case) + \"\\n\")  \n",
    "\n",
    "    # Print the number of detected issues  \n",
    "    print(f\"Total correct cases: {len(correct_cases)}\")  \n",
    "    print(f\"Total incorrect cases: {len(incorrect_cases)}\")  \n",
    "    print(\"Reasons for incorrectness:\")  \n",
    "    for reason, count in reason_counter.items():  \n",
    "        print(f\"{reason}: {count}\")  \n",
    "\n",
    "process_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1066, 766167)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "# Paths\n",
    "input_file = \"/nobackup/zefan/projects/VLGen/LlamaGen/metadata_correct.jsonl\"\n",
    "output_val_file = \"/nobackup/zefan/projects/VLGen/LlamaGen/new_1117_validation_set.jsonl\"\n",
    "output_train_file = \"/nobackup/zefan/projects/VLGen/LlamaGen/new_1117_train_set.jsonl\"\n",
    "\n",
    "# Load the input JSONL file\n",
    "with open(input_file, \"r\") as f:\n",
    "    data = [json.loads(line.strip()) for line in f]\n",
    "\n",
    "# Randomly split 500 samples for validation, rest for training\n",
    "random.seed(42)  # For reproducibility\n",
    "random.shuffle(data)\n",
    "val_data = data[:500]\n",
    "train_data = data[500:]\n",
    "\n",
    "# Function to convert data format\n",
    "def convert_to_new_format(data, starting_idx=0):\n",
    "    new_data = []\n",
    "    global_idx = starting_idx\n",
    "    for item in data:\n",
    "        for segment_idx, (mask_path, obj) in enumerate(zip(item[\"mask_path\"], item[\"sam_objects\"])):\n",
    "            new_sample = {\n",
    "                \"global_idx\": global_idx,\n",
    "                \"source_image\": item[\"source_img\"],\n",
    "                \"image_path\": mask_path,\n",
    "                \"objects\": obj,\n",
    "                \"segment_idx\": segment_idx,\n",
    "                \"input_text\": f\"<image>\\n{item['caption']}\"\n",
    "            }\n",
    "            new_data.append(new_sample)\n",
    "            global_idx += 1\n",
    "    return new_data\n",
    "\n",
    "# Convert validation and training data\n",
    "val_converted = convert_to_new_format(val_data, starting_idx=0)\n",
    "train_converted = convert_to_new_format(train_data, starting_idx=len(val_converted))\n",
    "\n",
    "# Save converted data to new JSONL files\n",
    "with open(output_val_file, \"w\") as val_out, open(output_train_file, \"w\") as train_out:\n",
    "    for item in val_converted:\n",
    "        val_out.write(json.dumps(item) + \"\\n\")\n",
    "    for item in train_converted:\n",
    "        train_out.write(json.dumps(item) + \"\\n\")\n",
    "\n",
    "# Summary\n",
    "len(val_converted), len(train_converted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global_idx': 1066,\n",
       " 'source_image': '/nobackup/zefan/projects/VLGen/segment_results_sam/cnt_10000_1000000000_0_39_0/0000000706/ori.jpg',\n",
       " 'image_path': '/nobackup/zefan/projects/VLGen/segment_results_sam/cnt_10000_1000000000_0_39_0/0000000706/mask_bride.jpg',\n",
       " 'objects': 'bride',\n",
       " 'segment_idx': 0,\n",
       " 'input_text': '<image>\\nA bride being photographed on a scenic dock surrounded by decorative arches.'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_converted[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "mask_paths= [\"/nobackup/zefan/projects/VLGen/segment_results_imgnet/cnt_0_100000000_0_2_0/0000000331/mask_wardrobe.jpg\", \"/nobackup/zefan/projects/VLGen/segment_results_imgnet/cnt_0_100000000_0_2_0/0000000331/mask_clothes.jpg\", \"/nobackup/zefan/projects/VLGen/segment_results_imgnet/cnt_0_100000000_0_2_0/0000000331/mask_drawer.jpg\"]\n",
    "def is_mask_valid(mask_paths):  \n",
    "    if len(mask_paths) == 1:  \n",
    "        return True, None  # Single mask is always valid  \n",
    "    elif len(mask_paths) == 0:  \n",
    "        return False, \"no_masks\"  \n",
    "\n",
    "    # Load masks  \n",
    "    masks = [Image.open(path) for path in mask_paths]  \n",
    "    mask_sizes = [np.sum(np.array(mask) > 0) for mask in masks]  \n",
    "    total_pixels = masks[0].size[0] * masks[0].size[1]  \n",
    "\n",
    "    # Check similarity  \n",
    "    # for i, mask1 in enumerate(masks):  \n",
    "    #     for j, mask2 in enumerate(masks):  \n",
    "    #         if i < j and is_similar(mask1, mask2):  # Check similarity  \n",
    "    #             return False, \"similar_masks\"  \n",
    "\n",
    "    # Check size condition  \n",
    "    for i, size in enumerate(mask_sizes):  \n",
    "        ratio = size / total_pixels  \n",
    "        if ratio < 0.05:  \n",
    "            return False, \"mask_too_small\" ,masks ,i\n",
    "        # if ratio > 0.95:  \n",
    "        #     return False, \"mask_too_large\"  \n",
    "\n",
    "    return True, None  \n",
    "\n",
    "_,_,masks,i = is_mask_valid(mask_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262144"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " masks[0].size[0] * masks[0].size[1]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254807"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.array(mask[1]) == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw  \n",
    "import numpy as np  \n",
    "\n",
    "def create_image_with_polygon(p):  \n",
    "    # 确保 p 值在 0 到 100 之间  \n",
    "    if not (0 <= p <= 100):  \n",
    "        raise ValueError(\"p must be between 0 and 100\")  \n",
    "    \n",
    "    # 图像大小  \n",
    "    size = (512, 512)  \n",
    "    total_pixels = size[0] * size[1]  \n",
    "    \n",
    "    # 计算应该变白的像素数  \n",
    "    white_pixels_count = int(total_pixels * (p / 100.0))  \n",
    "\n",
    "    # 创建一个黑色的图像  \n",
    "    image = Image.new(\"L\", size, 0)  \n",
    "    draw = ImageDraw.Draw(image)  \n",
    "    \n",
    "    # 选择一个简单的正六边形作为多边形  \n",
    "    num_sides = 6  \n",
    "    \n",
    "    # 初步假设使用一个大小足够大的中心多边形, 然后调整以适应p%  \n",
    "    # 这里假设使用边长和几何方法计算所需面积后调整  \n",
    "    # 考虑正多边形面积公式: (3*np.sqrt(3)*(edge_length**2))/2  \n",
    "    approx_edge_length = np.sqrt((2 * white_pixels_count) / (3 * np.sqrt(3)))  \n",
    "\n",
    "    # 将多边形设置在图像的中心  \n",
    "    center_x, center_y = size[0] // 2, size[1] // 2  \n",
    "    angle_step = 360 / num_sides  \n",
    "    \n",
    "    # 创建多边形顶点  \n",
    "    points = [  \n",
    "        (  \n",
    "            center_x + approx_edge_length * np.cos(np.radians(angle_step * i)),  \n",
    "            center_y + approx_edge_length * np.sin(np.radians(angle_step * i))  \n",
    "        )  \n",
    "        for i in range(num_sides)  \n",
    "    ]  \n",
    "\n",
    "    # 画多边形  \n",
    "    draw.polygon(points, fill=255)  \n",
    "\n",
    "    return image  \n",
    "\n",
    "# 使用示例：创建一个图像，中间是面积为30% 的白色多边形  \n",
    "polygon_image = create_image_with_polygon(95)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/nobackup/zefan/projects/VLGen/LlamaGen/dreambench_plus_valid.jsonl'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert dreambench_plus\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Define input and output paths\n",
    "base_path = \"/nobackup/zefan/projects/VLGen/LlamaGen\"\n",
    "captions_folder = os.path.join(base_path, \"data/captions\")\n",
    "images_folder = os.path.join(base_path, \"data/images\")\n",
    "output_file = os.path.join(base_path, \"dreambench_plus_valid.jsonl\")\n",
    "\n",
    "# Initialize global_idx and list to store dataset\n",
    "global_idx = 0\n",
    "dataset = []\n",
    "\n",
    "# Traverse the captions folder\n",
    "for root, _, files in os.walk(captions_folder):\n",
    "    for file in files:\n",
    "        if file.endswith(\".txt\"):\n",
    "            txt_path = os.path.join(root, file)\n",
    "            image_relative_path = os.path.relpath(root, captions_folder)\n",
    "            image_file = file.replace(\".txt\", \".jpg\")\n",
    "            image_path = os.path.join(images_folder, image_relative_path, image_file)\n",
    "            \n",
    "            # Read the txt file\n",
    "            with open(txt_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                if len(lines) > 1:\n",
    "                    object_name = lines[0].strip()\n",
    "                    captions = [line.strip() for line in lines[1:]]\n",
    "                    \n",
    "                    # Create dataset instances for each caption\n",
    "                    for caption in captions:\n",
    "                        instance = {\n",
    "                            \"global_idx\": global_idx,\n",
    "                            \"source_image\": image_path,\n",
    "                            \"image_path\": image_path,\n",
    "                            \"objects\": object_name,\n",
    "                            \"segment_idx\": 0,\n",
    "                            \"input_text\": f\"<image>\\n{caption}\"\n",
    "                        }\n",
    "                        dataset.append(instance)\n",
    "                        global_idx += 1\n",
    "\n",
    "# Save the dataset to a jsonl file\n",
    "with open(output_file, 'w') as f:\n",
    "    for entry in dataset:\n",
    "        json.dump(entry, f)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "# Confirm completion\n",
    "output_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MMA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
